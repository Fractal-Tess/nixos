# Hashdeep - File Hashing and Auditing Tool

## Overview
Hashdeep is a cross-platform tool for computing and auditing:
- Multiple hash algorithms
- File integrity verification
- Directory auditing
- Digital forensics
- File change detection
- Hash comparison

## Basic Usage

### Compute Hashes
```bash
# Compute hashes for single file
hashdeep file.txt

# Compute hashes with multiple algorithms
hashdeep -md5,sha1,sha256 file.txt

# Compute hashes for directory recursively
hashdeep -r /path/to/directory

# Compute hashes for multiple files
hashdeep file1.txt file2.txt file3.txt
```

### Hash Algorithms
```bash
# MD5 hashes
hashdeep -md5 file.txt

# SHA1 hashes
hashdeep -sha1 file.txt

# SHA256 hashes
hashdeep -sha256 file.txt

# Multiple algorithms
hashdeep -md5,sha1,sha256 file.txt

# All supported algorithms
hashdeep -md5,sha1,sha256,sha512,tiger,whirlpool file.txt
```

## File Hashing

### Single File Operations
```bash
# Compute hash of single file
hashdeep file.txt

# Output in specific format
hashdeep -f output.txt file.txt

# Relative path hashing
hashdeep -rl .  # Current directory recursively

# Absolute path hashing
hashdeep -ra /path/to/directory
```

### Directory Hashing
```bash
# Recursive directory hashing
hashdeep -r /path/to/directory

# Hash specific file types
hashdeep -r /path/to/directory -type f -name "*.log"

# Hash with file size info
hashdeep -s /path/to/directory

# Hash with timestamps
hashdeep -t /path/to/directory
```

### Hash Output Formats
```bash
# Default format
hashdeep file.txt

# CSV format
hashdeep -c csv file.txt

# DFXML format (digital forensics)
hashdeep -d file.txt

# Custom format
hashdeep -f custom_format.txt file.txt
```

## Hash Auditing

### Create Hash Database
```bash
# Create hash database
hashdeep -c md5,sha1 /path/to/directory > hashlist.txt

# Create database with relative paths
hashdeep -rl . > hashlist.txt

# Create database with file sizes
hashdeep -s -r /path/to/directory > hashlist.txt

# Create database for auditing
hashdeep -a -r /path/to/directory > audit_hashes.txt
```

### Verify Against Hash Database
```bash
# Verify files against hash database
hashdeep -a -r /path/to/directory -v hashlist.txt

# Audit mode
hashdeep -a -r /path/to/directory -w hashlist.txt

# Check for modified files
hashdeep -a -r /path/to/directory -m hashlist.txt

# Report only mismatches
hashdeep -a -r /path/to/directory -e hashlist.txt
```

### Integrity Checking
```bash
# Check file integrity
hashdeep -a file.txt -v hashlist.txt

# Check directory integrity
hashdeep -a -r /path/to/directory -v hashlist.txt

# Check with specific algorithms
hashdeep -a -md5,sha256 -r /path/to/directory -v hashlist.txt

# Generate audit report
hashdeep -a -r /path/to/directory -v hashlist.txt > audit_report.txt
```

## Advanced Features

### File Matching
```bash
# Compute hashes for specific file types
hashdeep -r /path -type f -name "*.exe"

# Exclude specific directories
hashdeep -r /path --exclude=/path/exclude

# Follow symbolic links
hashdeep -rL /path/to/directory

# Don't follow symbolic links
hashdeep -rP /path/to/directory
```

### Hash Comparison
```bash
# Compare two hash sets
hashdeep -c hash1.txt hash2.txt

# Find matching files
hashdeep -m hashlist.txt /path/to/files

# Find different files
hashdeep -x hashlist.txt /path/to/files

# Compare directories
hashdeep -r /dir1 -r /dir2
```

### Bulk Operations
```bash
# Process multiple directories
for dir in /path/to/dir*; do
    hashdeep -r "$dir" > "${dir##*/}_hashes.txt"
done

# Parallel processing
find /path -type f | xargs -P 4 -I {} hashdeep {}
```

## Digital Forensics

### Evidence Collection
```bash
# Create forensic hash of directory
hashdeep -md5,sha1 -r /evidence > evidence_hashes.txt

# Create timeline of file changes
hashdeep -t -r /evidence > evidence_timeline.txt

# Hash with full metadata
hashdeep -t -s -r /evidence > evidence_full.txt
```

### File Analysis
```bash
# Hash known good files
hashdeep -r /system/known_good > known_hashes.txt

# Hash suspicious files
hashdeep -r /suspicious/ > suspicious_hashes.txt

# Compare against known bad files
hashdeep -m known_malware_hashes.txt /suspicious/
```

### Incident Response
```bash
# Quick hash of system files
hashdeep -r /bin /sbin /usr/bin /usr/sbin > system_hashes.txt

# Hash configuration files
hashdeep -r /etc > config_hashes.txt

# Hash user data
hashdeep -r /home > user_hashes.txt
```

## Practical Examples

### System Integrity Monitoring
```bash
#!/bin/bash
# System integrity monitoring script

directory="/bin"
baseline="system_baseline.txt"
current="system_current.txt"
report="integrity_report.txt"

# Create baseline if it doesn't exist
if [ ! -f "$baseline" ]; then
    echo "Creating baseline..."
    hashdeep -r "$directory" > "$baseline"
    echo "Baseline created: $baseline"
    exit 0
fi

# Check current state
echo "Checking current state..."
hashdeep -r "$directory" > "$current"

# Compare with baseline
echo "Comparing with baseline..."
hashdeep -a -r "$directory" -v "$baseline" > "$report"

# Show results
if [ -s "$report" ]; then
    echo "CHANGES DETECTED:"
    cat "$report"
else
    echo "No changes detected."
fi
```

### File Verification Script
```bash
#!/bin/bash
# File verification script

hashfile="$1"
directory="$2"

if [ -z "$hashfile" ] || [ -z "$directory" ]; then
    echo "Usage: $0 <hashfile> <directory>"
    exit 1
fi

echo "Verifying files in $directory against $hashfile"

# Verify files
hashdeep -a -r "$directory" -v "$hashfile"

# Check exit status
if [ $? -eq 0 ]; then
    echo "All files verified successfully."
else
    echo "Verification failed. Some files may be modified or missing."
fi
```

### Batch Hashing Script
```bash
#!/bin/bash
# Batch hashing script

input_dir="$1"
output_dir="hashes"

if [ -z "$input_dir" ]; then
    echo "Usage: $0 <input_directory>"
    exit 1
fi

mkdir -p "$output_dir"

# Hash each subdirectory separately
for subdir in "$input_dir"/*; do
    if [ -d "$subdir" ]; then
        dirname=$(basename "$subdir")
        echo "Hashing $dirname..."
        hashdeep -r "$subdir" > "$output_dir/${dirname}_hashes.txt"
    fi
done

echo "Hashing complete. Results in $output_dir/"
```

## Hash Database Management

### Create Hash Database
```bash
# Initialize hash database
hashdeep -c md5,sha1,sha256 /path/to/files > hash_database.txt

# Add comments to database
echo "# Hash database created $(date)" >> hash_database.txt
echo "# Source: /path/to/files" >> hash_database.txt
```

### Update Hash Database
```bash
# Update existing database
hashdeep -r /path/to/files >> hash_database.txt

# Merge multiple hash databases
cat hash1.txt hash2.txt | sort -u > merged_hashes.txt

# Remove duplicates
sort -u hash_database.txt > hash_database_unique.txt
```

### Search Hash Database
```bash
# Search for specific hash
grep "d41d8cd98f00b204e9800998ecf8427e" hash_database.txt

# Search for file pattern
grep "filename.txt" hash_database.txt

# Count unique files
wc -l hash_database.txt
```

## Integration with Other Tools

### Combine with find
```bash
# Hash specific file types
find /path -name "*.log" -exec hashdeep {} +

# Hash files modified recently
find /path -mtime -7 -exec hashdeep {} +

# Hash files by size
find /path -size +1M -exec hashdeep {} +
```

### Combine with sort and uniq
```bash
# Find duplicate files
hashdeep -r /path | sort | uniq -d

# Create sorted hash list
hashdeep -r /path | sort > sorted_hashes.txt

# Remove duplicate hashes
hashdeep -r /path | sort -u > unique_hashes.txt
```

## Performance Optimization

### Parallel Processing
```bash
# Use multiple cores
find /path -type f | xargs -P 4 -I {} hashdeep {}

# Limit file size
find /path -size -100M -exec hashdeep {} +
```

### Efficient Hashing
```bash
# Hash only specific file types
hashdeep -r /path -type f -name "*.exe" -name "*.dll"

# Exclude temporary files
hashdeep -r /path --exclude="*.tmp" --exclude="*.temp"

# Use memory efficiently
hashdeep -r /path -B 1000000
```

## Troubleshooting

### Common Issues
```bash
# Permission denied
sudo hashdeep -r /root

# File not found
hashdeep -L /path/to/broken/link

# Too many files
ulimit -n 65536
hashdeep -r /large/directory
```

### Performance Issues
```bash
# Slow processing
# Use specific file types
hashdeep -r /path -name "*.txt"

# Memory issues
# Process in smaller batches
find /path -type f | split -l 1000 - chunk_
for chunk in chunk_*; do
    hashdeep $(cat $chunk)
done
```

## Tips
- Use multiple hash algorithms for better security
- Create baselines before making changes
- Store hash databases securely
- Use absolute paths for consistency
- Include file metadata for forensic analysis
- Regularly update hash databases
- Use appropriate hash algorithms for your needs
- Consider performance when hashing large datasets
- Document hash database creation and maintenance
- Use hashdeep for digital evidence preservation
- Combine with other tools for comprehensive analysis