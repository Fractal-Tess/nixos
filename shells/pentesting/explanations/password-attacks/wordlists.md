# Wordlists - Password Dictionaries

## Overview
Wordlists are collections of words, phrases, and character combinations used for:
- Password cracking
- Directory/file brute-forcing
- Subdomain enumeration
- Parameter fuzzing
- Username enumeration

## Available Wordlists

### System Wordlists
```bash
# Common wordlist locations
/usr/share/wordlists/
/usr/share/dirb/wordlists/
/usr/share/seclists/
/usr/share/dict/
```

### Popular Wordlists
```bash
# RockYou wordlist (most common passwords)
/usr/share/wordlists/rockyou.txt

# Common passwords
/usr/share/wordlists/common-passwords.txt

# Directory names
/usr/share/dirb/wordlists/common.txt

# Subdomain lists
/usr/share/seclists/Discovery/DNS/subdomains-top1million-110000.txt

# Username lists
/usr/share/seclists/Usernames/top-usernames-shortlist.txt
```

## Wordlist Management

### Wordlist Analysis
```bash
# Count lines in wordlist
wc -l wordlist.txt

# Find unique entries
sort -u wordlist.txt > unique_wordlist.txt

# Remove duplicates and sort
sort wordlist.txt | uniq > dedup_wordlist.txt

# Find word frequency
sort wordlist.txt | uniq -c | sort -nr > frequency.txt
```

### Wordlist Filtering
```bash
# Filter by length
awk 'length($0) >= 8 && length($0) <= 12' wordlist.txt > filtered.txt

# Filter to alphanumeric only
grep -E '^[a-zA-Z0-9]+$' wordlist.txt > alnum.txt

# Filter to lowercase only
grep -E '^[a-z]+$' wordlist.txt > lowercase.txt

# Remove common words
grep -v -E '^(the|and|or|of|to|in|for|on|with|at|by|from)$' wordlist.txt > filtered.txt
```

### Wordlist Generation
```bash
# Create numbered variations
for i in {1..999}; do echo "password$i"; done > numbers.txt

# Create leet speak variations
sed 's/a/@/g; s/e/3/g; s/i/1/g; s/o/0/g; s/s/$/g' wordlist.txt > leet.txt

# Create capitalized versions
sed 's/^./\U&/' wordlist.txt > capitalized.txt

# Create combination patterns
cat wordlist1.txt wordlist2.txt | while read line; do echo "${line}123"; done > combo.txt
```

## Wordlist Categories

### Password Wordlists
```bash
# Common passwords
/usr/share/wordlists/rockyou.txt
/usr/share/wordlists/darkweb2017-top10000.txt

# Pattern-based passwords
/usr/share/wordlists/patterns.txt

# Keyboard patterns
qwerty.txt
123456789.txt
```

### Directory and File Wordlists
```bash
# Common directories
/usr/share/dirb/wordlists/common.txt
/usr/share/dirb/wordlists/directory-list-2.3-medium.txt

# Backup files
backup.txt
bak.txt
old.txt

# Config files
config.txt
conf.txt
cfg.txt
```

### Subdomain Wordlists
```bash
# Common subdomains
/usr/share/seclists/Discovery/DNS/subdomains-top1million-110000.txt

# Technology-specific
api-subdomains.txt
admin-subdomains.txt
dev-subdomains.txt
```

### Username Wordlists
```bash
# Common usernames
/usr/share/seclists/Usernames/top-usernames-shortlist.txt

# Name-based
first-names.txt
last-names.txt

# Role-based
admin.txt
user.txt
guest.txt
```

## Creating Custom Wordlists

### Target-Specific Wordlists
```bash
# Company-specific wordlist
echo -e "company\nCompany\nCOMPANY\ncompany123\nCompany2024" > company_wordlist.txt

# Application-specific wordlist
echo -e "admin\nadministrator\ntest\ndemo\napi\nv1\nv2" > app_wordlist.txt

# Location-based wordlist
echo -e "cityname\ncityname123\ncityname2024\nlocation" > location_wordlist.txt
```

### Combining Wordlists
```bash
# Merge multiple wordlists
cat wordlist1.txt wordlist2.txt wordlist3.txt | sort -u > combined.txt

# Create prioritized wordlist
head -1000 rockyou.txt > high_priority.txt
tail -1000 rockyou.txt > low_priority.txt
cat high_priority.txt custom_wordlist.txt low_priority.txt > prioritized.txt
```

### Pattern-Based Generation
```bash
# Year-based patterns
for year in {2020..2024}; do
    cat base_words.txt | while read word; do
        echo "${word}${year}"
        echo "${word}_${year}"
        echo "${word}!@#$year"
    done
done > year_patterns.txt

# Leet speak generator
cat wordlist.txt | while read word; do
    echo "$word"  # Original
    echo "${word^}"  # Capitalized
    echo "${word^^}"  # Uppercase
    echo "${word}123"  # With numbers
done > variations.txt
```

## Wordlist Optimization

### Size Optimization
```bash
# Create smaller version for quick tests
head -10000 rockyou.txt > rockyou_small.txt

# Create medium version
head -100000 rockyou.txt > rockyou_medium.txt

# Create large version
head -1000000 rockyou.txt > rockyou_large.txt
```

### Quality Improvement
```bash
# Remove very short entries
awk 'length($0) >= 6' wordlist.txt > min6.txt

# Remove very long entries
awk 'length($0) <= 20' wordlist.txt <= 20.txt

# Remove non-printable characters
grep -P '^[[:print:]]+$' wordlist.txt > printable.txt

# Remove duplicates while preserving order
awk '!seen[$0]++' wordlist.txt > unique_ordered.txt
```

## Wordlists for Different Tools

### Hashcat Wordlists
```bash
# Hashcat rules
hashcat --stdout -r /usr/share/hashcat/rules/best64.rule rockyou.txt > expanded.txt

# Create mask-protected wordlist
hashcat --stdout -r /usr/share/hashcat/rules/d3ad0ne.rule rockyou.txt > d3ad0ne.txt
```

### John the Ripper Wordlists
```bash
# John rules
john --wordlist=rockyou.txt --rules --stdout > john_expanded.txt

# Incremental mode preparation
john --incremental=ASCII --stdout > incremental.txt
```

### Hydra Wordlists
```bash
# Service-specific usernames
echo -e "admin\nadministrator\nroot\nuser\nguest\ntest" > hydra_users.txt

# Service-specific passwords
echo -e "password\n123456\nadmin\nroot\ntest\npassword123" > hydra_passwords.txt
```

## Practical Examples

### Quick Password Attack
```bash
# Use top 1000 passwords
head -1000 /usr/share/wordlists/rockyou.txt > quick_attack.txt

# Use with John
john --wordlist=quick_attack.txt hash_file.txt

# Use with Hashcat
hashcat -a 0 -m 0 hash_file.txt quick_attack.txt
```

### Directory Brute-forcing
```bash
# Quick directory scan
head -1000 /usr/share/dirb/wordlists/common.txt > quick_dirs.txt

# Use with Gobuster
gobuster dir -u http://target.com -w quick_dirs.txt

# Use with FFUF
ffuf -w quick_dirs.txt -u http://target.com/FUZZ
```

### Subdomain Enumeration
```bash
# Common subdomains
head -10000 /usr/share/seclists/Discovery/DNS/subdomains-top1million-110000.txt > quick_subs.txt

# Use with Sublist3r or similar tools
python3 sublist3r.py -d target.com -w quick_subs.txt
```

## Automation Scripts

### Wordlist Generator
```bash
#!/bin/bash
# Custom wordlist generator

base_wordlist="$1"
output_file="$2"

if [ -z "$base_wordlist" ] || [ -z "$output_file" ]; then
    echo "Usage: $0 <input_wordlist> <output_file>"
    exit 1
fi

# Create variations
echo "Creating password variations..."

# Original words
cat "$base_wordlist" > "$output_file"

# Capitalized
sed 's/^./\U&/' "$base_wordlist" >> "$output_file"

# Uppercase
awk '{print toupper($0)}' "$base_wordlist" >> "$output_file"

# With numbers
sed 's/$/123/' "$base_wordlist" >> "$output_file"

# With years
for year in {2020..2024}; do
    sed "s/$/$year/" "$base_wordlist" >> "$output_file"
done

# Remove duplicates
sort -u "$output_file" > "${output_file}.tmp"
mv "${output_file}.tmp" "$output_file"

echo "Wordlist created: $output_file"
echo "Total entries: $(wc -l < "$output_file")"
```

### Wordlist Merger
```bash
#!/bin/bash
# Merge and optimize multiple wordlists

output_file="combined_wordlist.txt"

# Merge all .txt files in current directory
cat *.txt | sort -u > "$output_file"

# Filter by length (6-20 characters)
awk 'length($0) >= 6 && length($0) <= 20' "$output_file" > filtered.txt

# Create size variations
head -1000 filtered.txt > small.txt
head -10000 filtered.txt > medium.txt
head -100000 filtered.txt > large.txt

echo "Wordlist variations created:"
echo "small.txt: $(wc -l < small.txt) entries"
echo "medium.txt: $(wc -l < medium.txt) entries"
echo "large.txt: $(wc -l < large.txt) entries"
```

## Tips
- Start with smaller wordlists for quick testing
- Use targeted wordlists based on reconnaissance information
- Combine different wordlist types for comprehensive coverage
- Remove duplicates to optimize performance
- Consider password policies when creating wordlists
- Use wordlists that match the target's language/culture
- Regularly update wordlists with new common passwords
- Be mindful of storage space for large wordlists
- Use compressed formats for storage when possible
- Document wordlist sources and creation methods