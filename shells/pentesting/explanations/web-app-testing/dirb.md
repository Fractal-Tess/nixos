# DIRB - Web Content Scanner

## Overview
DIRB is a web content scanner that searches for existing (or hidden) web objects by brute-forcing:
- Directory names
- File names
- Web applications
- Hidden resources

## Basic Usage

### Simple Scanning
```bash
# Basic directory scan
dirb http://target.com

# Scan with specific wordlist
dirb http://target.com /usr/share/wordlists/common.txt

# Scan with extensions
dirb http://target.com /usr/share/wordlists/common.txt -x .php,.html,.txt
```

### Target Specification
```bash
# HTTP (default port 80)
dirb http://target.com

# HTTPS (default port 443)
dirb https://target.com

# Specific port
dirb http://target.com:8080

# Specific path
dirb http://target.com/admin/
```

## Wordlists and Extensions

### Using Wordlists
```bash
# Use specific wordlist
dirb http://target.com /path/to/wordlist.txt

# Use multiple wordlists
dirb http://target.com wordlist1.txt wordlist2.txt

# Use built-in wordlists
dirb http://target.com -w /usr/share/dirb/wordlists/common.txt
```

### File Extensions
```bash
# Single extension
dirb http://target.com -x .php

# Multiple extensions
dirb http://target.com -x .php,.html,.txt,.bak

# Extension ranges
dirb http://target.com -x .php,.asp,.jsp

# Case sensitive extensions
dirb http://target.com -X .PHP,.ASP,.JSP
```

## Scanning Options

### Speed and Performance
```bash
# Set delay between requests (milliseconds)
dirb http://target.com -z 1000

# Set number of concurrent threads
dirb http://target.com -c 10

# Disable recursive scanning
dirb http://target.com -r

# Enable recursive scanning (default depth 1)
dirb http://target.com -R
```

### Output Options
```bash
# Save output to file
dirb http://target.com -o results.txt

# Save output with timestamp
dirb http://target.com -o results_$(date +%Y%m%d_%H%M%S).txt

# Quiet mode (no progress display)
dirb http://target.com -S

# Verbose mode (show all requests)
dirb http://target.com -v
```

## HTTP Options

### Headers and Authentication
```bash
# Set User-Agent header
dirb http://target.com -a "CustomBot/1.0"

# Set Cookie header
dirb http://target.com -c "sessionid=abc123; auth_token=xyz"

# HTTP Basic Authentication
dirb http://target.com -u username -p password

# Custom headers
dirb http://target.com -H "X-Custom-Header: Value"
```

### Proxy Support
```bash
# Use HTTP proxy
dirb http://target.com -P http://proxy.com:8080

# Use proxy with authentication
dirb http://target.com -P http://user:pass@proxy.com:8080
```

### HTTP Options
```bash
# Follow redirects
dirb http://target.com -N

# Ignore SSL certificate errors
dirb https://target.com -i

# Set HTTP method (GET by default)
dirb http://target.com -m POST

# Set connection timeout
dirb http://target.com -l 10
```

## Advanced Scanning

### Recursive Scanning
```bash
# Set recursion depth
dirb http://target.com -R -l 3

# Recursive scanning with extensions
dirb http://target.com -R -x .php,.html -l 2

# Exclude certain directories from recursion
dirb http://target.com -R -X "images,css,js"
```

### Target Ranges
```bash
# Scan multiple targets
dirb http://target1.com,http://target2.com

# Read targets from file
echo "http://target1.com
http://target2.com" > targets.txt
dirb -L targets.txt

# Scan multiple paths on same target
dirb http://target.com/ -l paths.txt
```

## Output Analysis

### Status Code Filtering
```bash
# Show only specific status codes
dirb http://target.com | grep -E "200|301|302"

# Show error codes
dirb http://target.com | grep -E "403|404|500"

# Count findings
dirb http://target.com -o results.txt && grep "==" results.txt | wc -l
```

### Result Processing
```bash
# Extract URLs only
dirb http://target.com -o results.txt && grep "http" results.txt | awk '{print $1}'

# Extract directories only
dirb http://target.com -o results.txt | grep "/$" | awk '{print $1}'

# Sort and deduplicate results
dirb http://target.com -o results.txt && sort -u results.txt
```

## Practical Examples

### Quick Web Scan
```bash
# Fast scan with common directories
dirb http://target.com /usr/share/dirb/wordlists/common.txt -x .php,.html,.txt
```

### Deep Scan
```bash
# Comprehensive recursive scan
dirb http://target.com /usr/share/dirb/wordlists/big.txt -x .php,.asp,.jsp,.html,.txt,.bak,.old -R -l 3
```

### Hidden Admin Panel Discovery
```bash
# Search for admin panels
dirb http://target.com /usr/share/dirb/wordlists/admin.txt -x .php,.asp,.jsp
```

### Backup File Discovery
```bash
# Find backup files
dirb http://target.com /usr/share/dirb/wordlists/common.txt -x .bak,.backup,.old,.tmp,.log
```

### API Endpoint Discovery
```bash
# Find API endpoints
dirb http://target.com/api/ /usr/share/dirb/wordlists/common.txt -x .json,.xml
```

## Custom Wordlists

### Creating Wordlists
```bash
# Create custom wordlist
echo -e "admin\nadministrator\ntest\ndemo\napi\nv1\nv2" > custom.txt

# Combine multiple wordlists
cat wordlist1.txt wordlist2.txt | sort -u > combined.txt

# Generate wordlist from pattern
echo -e "admin\nadmin1\nadmin2\nadmin3" > admin_numbers.txt
```

### Wordlist Optimization
```bash
# Remove common words
grep -v -E "^(the|and|or|of|to|in|for|on|with|at|by|from)$" wordlist.txt > filtered.txt

# Sort and remove duplicates
sort -u wordlist.txt > unique.txt

# Filter by length
awk 'length($0) >= 3 && length($0) <= 10' wordlist.txt > sized.txt
```

## Automation Scripts

### Mass Scanning
```bash
#!/bin/bash
# Scan multiple targets
targets=("target1.com" "target2.com" "target3.com")
wordlist="/usr/share/dirb/wordlists/common.txt"

for target in "${targets[@]}"; do
    echo "Scanning $target..."
    dirb "http://$target" "$wordlist" -x .php,.html,.txt -o "${target}_results.txt"
done
```

### Scheduled Scanning
```bash
#!/bin/bash
# Daily scan with email notification
target="target.com"
wordlist="/usr/share/dirb/wordlists/big.txt"
date=$(date +%Y%m%d)

dirb "http://$target" "$wordlist" -x .php,.html,.txt -o "scan_${date}.txt"

# Send email with results
mail -s "DIRB scan results for $target" admin@example.com < "scan_${date}.txt"
```

## Tips
- Start with common wordlists for quick results
- Use recursive scanning to discover hidden subdirectories
- Combine with other tools for comprehensive assessment
- Be mindful of server load and potential blocking
- Use appropriate delays to avoid detection
- Save results for comparison and tracking
- Consider using multiple wordlists for thorough coverage
- Respect rate limits and server capabilities